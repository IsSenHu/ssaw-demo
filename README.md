#SSAW(春夏秋冬)

--
### 1、统一认证
    资源对应一个微服务应用，
    一个客户端可以对应多个资源，
    一个资源对应多个作用域，
    一个作用域对应一个权限并且绑定了访问url。
    
####1.1（后台管理）分配权限流程：
    1、新建资源
    2、为资源新建作用域同时产生拦截url和权限
    3、新建客户端，设置资源、作用域等相关信息
    4、新建角色
    5、选择客户端和资源并且设置权限（作用域）
    6、为用户绑定角色，赋予权限
    
    7、前端判断用户是否登录，如果没有登录，引导进入登录页面

#### 2、消息队列
    - 缺点: 系统可用性降低、系统复杂性增加、一致性问题
    - 应用场景: 异步处理按、应用解耦、流量削峰
##### 2.1、消息队列模型
    1、P2P/点对点模式(Queue; 消息队列、发送者、接收者)
    2、发布订阅模式(Pub/Sub; 主题、发布者、订阅者)
#### 2.2、如何保证消息队列是高可用的
#### 2.3、造成重复消费的原因
    . 因为网络传输等等故障，确认信息没有传送到消息队列，导致消费队列不知道自己已经消费过该
    消息了，再次将消费者分发给其他的消费者
    1、给消息做一个唯一的主键，做数据库的insert操作
    2、拿这个消息到redist做set操作，因为无论set几次结果都一样
    3、用redis做消费记录
#### 2.4、如何保证消息的可靠性传输
    .生产者丢数据: 支持事务的队列可以开始事务
    .消息队列丢数据: 一般开启持久化磁盘的配置。这个持久化配置可以和confirm机制配合使用，你
    可以在消息持久化磁盘后，再给生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMq
    阵亡了，那么生产者就收不到Ack信号，生产者会自动重发。
    .消费者丢数据: 消费者丢数据一般是因为采用了自动确认消费模式。这种模式下，消费者会自动确认
    收到信息。这时rabbitMq就会立即将消息删除，这种情况下，如果消费者出现异常而未能处理消息，
    就会丢失该消息，采用手动确认消息即可。
#### 2.5、如何持久化
    - 将queue的持久化标识durable设置true，则代表是一个持久的队列
    - 发送消息到的时候将delivertMode=2
#### 2.6、如何保证消息的顺序性
#### 2.7、如何解决消息队列的数据积压
    -设立过期时间、直接丢弃数据、恢复消费者、临时扩容、快速消费
    
### kafka
    :Kafka是分布式发布-订阅消息系统。它最初由LinkedIn公司开发，使用Scala语言编写，之后
    成为Apach项目的一部分。Kafka是一个分布式的，可划分的，多订阅者，冗余备份的持久性日志服务。
    它主要用于处理活跃的流式数据。如果对实时性要求较高的话，可以使用这种方案。
#### kafka核心概念
    -Producer 特指消息的生产者
    -Consumer 特指消息的消费者
    -Consumer Group 消费者组，可以并行消费Topic中partition的消息
    -Broker 缓存代理，Kafka集群中的一台或多台服务器统称为broker
    -Topic 特指Kafka处理的消息源(feeds of messages)的不同分类
    -Partition Topic物理上的分组，一个Topic可以分为多个partition，每个partition是一个
    有序的队列。partition中的每条消息都会被分配一个有序的id(offset)
    -Message 消息，是通信的基本单位，每个Producer可以向一个Topic发布一些消息
    -Producers 消息和数据生产者，向Kafka的一个topic发布消息的过程叫做Producers
    -Consumers 消息和数据消费者，订阅Kafka并处理发布的消息的过程叫做Consumers